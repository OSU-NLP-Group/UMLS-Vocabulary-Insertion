{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d486b84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f4c424",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d89fff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84cbb0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, PreTrainedTokenizer, BertTokenizer\n",
    "\n",
    "pubmed_bert_tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe6b58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score,f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b67ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../src/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b06bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from UMLS import UMLS\n",
    "from RetrievalModule import RetrievalModule\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46dbe0b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "past_version = '2020AA'\n",
    "umls_version = '2020AB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c42bf8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mrconso_file = '../data/{}-ACTIVE/META_DL_V2/MRCONSO_MASTER.RRF'.format(umls_version)\n",
    "new_aui_set_file = '../data/AAAC_{}_vs_{}_AUIsList_TEST.txt'.format(past_version, umls_version)\n",
    "rba_filename = '../data/{}-ACTIVE/RBA_V2/AUI_COLOR.PICKLE'.format(umls_version)\n",
    "sort_filename = '../output/0/cambridgeltl_SapBERT-from-PubMedBERT-fulltext_candidates.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a41685",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "umls = UMLS(mrconso_file)\n",
    "_ = umls.get_new_aui_set(new_aui_set_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029508f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(umls.original_auis),len(umls.new_auis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90412ed0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "candidates = pickle.load(open(sort_filename,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3253c181",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62cd22b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load RBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f213b63e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mrconso = open(mrconso_file,'r').readlines()\n",
    "\n",
    "mrconso_dict = {}\n",
    "\n",
    "for line in mrconso:\n",
    "    line = line.split('|')\n",
    "    idn = line[0]\n",
    "    aui = line[4]\n",
    "    \n",
    "    mrconso_dict[int(idn)] = aui\n",
    "    \n",
    "colors = pickle.load(open(rba_filename,'rb'))\n",
    "\n",
    "color2aui = {}\n",
    "aui2color = {}\n",
    "\n",
    "for idn,color in tqdm(colors.items()):\n",
    "    \n",
    "    color_set = color2aui.get(color,set())\n",
    "    aui = mrconso_dict[idn]\n",
    "    \n",
    "    color_set.add(aui)\n",
    "\n",
    "    color2aui[color] = color_set\n",
    "    aui2color[aui] = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398cb37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rba_predicted_synonyms = {}\n",
    "\n",
    "for new_aui in tqdm(umls.new_auis):\n",
    "    \n",
    "    color = aui2color[new_aui]\n",
    "    predicted_auis = color2aui[color]\n",
    "    \n",
    "    filtered_preds = set()\n",
    "    \n",
    "    for pred in predicted_auis:\n",
    "        if pred != aui and pred not in umls.new_auis:\n",
    "            filtered_preds.add(pred)\n",
    "            \n",
    "    rba_predicted_synonyms[new_aui] = [umls.aui2cui[aui] for aui in filtered_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6324d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(rba_predicted_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c2e62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if '2020AB' in mrconso_file:\n",
    "    dataset_splits = pickle.load(open('../data/UMLS2020AB_SAPBERT_Source_Info_Official_Split_Basic.p','rb'))\n",
    "    dataset_splits = dataset_splits[['auis','split']].set_index('auis').to_dict()\n",
    "    dataset_splits = dataset_splits['split']\n",
    "else:\n",
    "    dataset_splits = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3415937a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Create dataframe with aui, true_cand (null included), true CUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d2083",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "old_cuis = set()\n",
    "\n",
    "for aui in tqdm(umls.original_auis):\n",
    "    \n",
    "    old_cuis.add(umls.aui2cui[aui])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c79eb00",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_cuis = set()\n",
    "\n",
    "for new_aui in umls.new_auis:\n",
    "    new_cui = umls.aui2cui[new_aui]\n",
    "    if new_cui not in old_cuis:\n",
    "        new_cuis.add(new_cui)\n",
    "    \n",
    "len(new_cuis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab348cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "for aui,cand_auis in tqdm(candidates.items()):\n",
    "    \n",
    "    query_str = umls.aui2str[aui]\n",
    "    cand_auis, cand_dists = cand_auis\n",
    "\n",
    "    true_cui = umls.aui2cui[aui]\n",
    "    cand_cuis = [umls.aui2cui[aui_cand] for aui_cand in cand_auis]\n",
    "    cand_strs = [umls.aui2str[aui_cand] for aui_cand in cand_auis]\n",
    "\n",
    "    null_or_cui = true_cui not in old_cuis\n",
    "\n",
    "    rba_cands = rba_predicted_synonyms[aui]\n",
    "\n",
    "    if dataset_splits is not None:\n",
    "        split = dataset_splits[aui]\n",
    "    else:\n",
    "        split = 'dev'\n",
    "\n",
    "    sem_group = umls.cui2sg[true_cui]\n",
    "\n",
    "    df.append((aui, query_str, true_cui, sem_group, cand_auis, cand_strs, cand_dists, cand_cuis, null_or_cui, rba_cands, split))\n",
    "    \n",
    "df = pd.DataFrame(df,columns=['aui','query_str', 'true_cui', 'sem_group', 'cand_auis', 'cand_strs', 'cand_dists', 'cand_cuis', 'null_or_cui', 'rba_cands', 'split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973818c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cui_sem_group_cui = df[['true_cui','sem_group']].drop_duplicates()\n",
    "validation = []\n",
    "testing = []\n",
    "\n",
    "test = 0.50\n",
    "\n",
    "for i,g in cui_sem_group_cui.groupby('sem_group'):\n",
    "    \n",
    "    perm_g = g.sample(len(g),random_state=np.random.RandomState(42)).true_cui.values\n",
    "    \n",
    "    validation.extend(perm_g[:len(g) - int(len(g)*(test))])\n",
    "    testing.extend(perm_g[len(g) - int(len(g)*test):])\n",
    "    \n",
    "    assert(validation[-1] != testing[0])\n",
    "    \n",
    "validation = set(validation)\n",
    "testing = set(testing)\n",
    "\n",
    "splits = []\n",
    "\n",
    "for cui in df.true_cui:\n",
    "    \n",
    "    if cui in testing:\n",
    "        splits.append('test')\n",
    "    else:\n",
    "        splits.append('dev')\n",
    "        \n",
    "        \n",
    "df['split'] = splits\n",
    "\n",
    "display(df.groupby('split').count())\n",
    "display(df.groupby('null_or_cui').count())\n",
    "display(df.groupby(['split','null_or_cui']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409c2352",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dev_df = df[[split in ['test'] for split in df.split]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dba2dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_performance_metrics = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8178fde",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## RBA Only Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae88cde9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rba_null_correct = []\n",
    "rba_preds = []\n",
    "\n",
    "for i, row in tqdm(dev_df.iterrows()):\n",
    "    query_aui = row.aui\n",
    "    true_cui = row.true_cui\n",
    "    null_cui = row.null_or_cui\n",
    "    \n",
    "    rba_cuis = rba_predicted_synonyms[query_aui]\n",
    "    \n",
    "    if len(rba_cuis) == 0:\n",
    "        rba_pred = 'null'\n",
    "        rba_preds.append(rba_pred)\n",
    "    \n",
    "        if null_cui:\n",
    "            rba_null_correct.append(1)\n",
    "        else:\n",
    "            rba_null_correct.append(0)\n",
    "    else:\n",
    "        rba_preds.append('cui')\n",
    "        if true_cui in rba_cuis:\n",
    "            rba_null_correct.append(1/len(rba_cuis))\n",
    "        else:\n",
    "            rba_null_correct.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed2c05",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dev_df['rba_correct'] = rba_null_correct\n",
    "dev_df['rba_pred'] = rba_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d01a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_recall_at_1 = dev_df.rba_correct.mean()\n",
    "print('Full R@1: {}'.format(overall_recall_at_1))\n",
    "null_recall = dev_df[dev_df.null_or_cui].rba_correct.mean()\n",
    "null_precision = dev_df[dev_df['rba_pred'] == 'null'].rba_correct.mean()\n",
    "print('NULL Recall: {}'.format(null_recall))\n",
    "print('NULL Precision: {}'.format(null_precision))\n",
    "non_null_recall_at_1 = dev_df[dev_df.null_or_cui == False].rba_correct.mean() \n",
    "print('Non-NULL Recall @1: {}'.format(non_null_recall_at_1))\n",
    "\n",
    "all_performance_metrics.append(('RBA Only',overall_recall_at_1, null_recall, null_precision, non_null_recall_at_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b181f6c2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## RBA + Ordering Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a98f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correct = []\n",
    "preds = []\n",
    "\n",
    "for i, row in tqdm(dev_df.iterrows()):\n",
    "    query_aui = row.aui\n",
    "    true_cui = row.true_cui\n",
    "    null_cui = row.null_or_cui\n",
    "    \n",
    "    rba_cuis = rba_predicted_synonyms[query_aui]\n",
    "    \n",
    "    sorted_cuis = row.cand_cuis\n",
    "    \n",
    "    if len(rba_cuis) == 0:\n",
    "        rba_pred = 'null'\n",
    "        preds.append(rba_pred)\n",
    "    \n",
    "        if null_cui:\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)\n",
    "    else:        \n",
    "        chosen_cui = None\n",
    "        \n",
    "        for sorted_cui in sorted_cuis:\n",
    "            if sorted_cui in rba_cuis:\n",
    "                chosen_cui = sorted_cui\n",
    "                break\n",
    "        \n",
    "        if chosen_cui is None:\n",
    "            preds.append('C-None')\n",
    "        else:\n",
    "            preds.append(chosen_cui)\n",
    "            \n",
    "        if true_cui == chosen_cui:\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfea372",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dev_df['rba_sorted_pred'] = preds\n",
    "dev_df['rba_sorted_correct'] = correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c64485e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overall_recall_at_1 = dev_df.rba_sorted_correct.mean()\n",
    "print('Full R@1: {}'.format(overall_recall_at_1))\n",
    "null_recall = dev_df[dev_df.null_or_cui].rba_sorted_correct.mean()\n",
    "null_precision = dev_df[dev_df['rba_pred'] == 'null'].rba_sorted_correct.mean()\n",
    "print('NULL Recall: {}'.format(null_recall))\n",
    "print('NULL Precision: {}'.format(null_precision))\n",
    "non_null_recall_at_1 = dev_df[dev_df.null_or_cui == False].rba_sorted_correct.mean() \n",
    "print('Non-NULL Recall @1: {}'.format(non_null_recall_at_1))\n",
    "\n",
    "all_performance_metrics.append(('RBA Plus Ranking', overall_recall_at_1, null_recall, null_precision, non_null_recall_at_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef908f67",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ordering Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cf48b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Obtained from 2020AB Insertion Set Training Set\n",
    "threshold = 0.9558532655239105 #SAPBERT\n",
    "# threshold = 0.9999997615814209 #PubMedBERT\n",
    "\n",
    "\n",
    "print('Threshold: {}'.format(threshold))\n",
    "\n",
    "correct = []\n",
    "preds = []\n",
    "\n",
    "for i, row in tqdm(dev_df.iterrows()):\n",
    "    query_aui = row.aui\n",
    "    true_cui = row.true_cui\n",
    "    null_cui = row.null_or_cui\n",
    "\n",
    "    sorted_cuis = row.cand_cuis\n",
    "    pred_cui = sorted_cuis[0]\n",
    "\n",
    "    closest_dist = row.cand_dists[0]\n",
    "\n",
    "    if closest_dist < threshold:\n",
    "        pred = 'null'\n",
    "        preds.append(pred)\n",
    "\n",
    "        if null_cui:\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)\n",
    "    else:        \n",
    "        preds.append(pred_cui)\n",
    "\n",
    "        if true_cui == pred_cui:\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)\n",
    "\n",
    "dev_df['sorted_pred'] = preds\n",
    "dev_df['sorted_correct'] = correct\n",
    "\n",
    "overall_recall_at_1 = dev_df.sorted_correct.mean()\n",
    "print('Full R@1: {}'.format(overall_recall_at_1))\n",
    "null_recall = dev_df[dev_df.null_or_cui].sorted_correct.mean()\n",
    "null_precision = dev_df[dev_df['sorted_pred'] == 'null'].sorted_correct.mean()\n",
    "print('NULL Recall: {}'.format(null_recall))\n",
    "print('NULL Precision: {}'.format(null_precision))\n",
    "non_null_recall_at_1 = dev_df[dev_df.null_or_cui == False].sorted_correct.mean() \n",
    "print('Non-NULL Recall @1: {}'.format(non_null_recall_at_1))\n",
    "print('=='*20)\n",
    "\n",
    "all_performance_metrics.append(('Ranking Only', overall_recall_at_1, null_recall, null_precision, non_null_recall_at_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f8bb9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(all_performance_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dd565e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Two-Step Re-Ranking Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89112548",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "directory = 'models'\n",
    "\n",
    "for add_rba_info in [True, False]:\n",
    "    max_len = 64\n",
    "    num_candidates = 50\n",
    "    subsets = {'train':10,'valid':None,'test':None}\n",
    "\n",
    "    data_name = 'uva_ins_eval_{}_max-len-{}_num-cands-{}_train-size-{}'.format(umls_version, max_len, num_candidates, subsets['train'])\n",
    "\n",
    "    if add_rba_info:\n",
    "        data_name += '_rba_info'\n",
    "        \n",
    "    data_name =  directory+'/'+data_name\n",
    "    \n",
    "    best_checkpoint = data_name+'/epoch_init'\n",
    "    \n",
    "    logits,labels = pickle.load(open('{}/eval_results.p'.format(best_checkpoint),'rb'))\n",
    "    dev_set = torch.load('{}/top50_candidates/valid.t7'.format(data_name))\n",
    "    query = pubmed_bert_tokenizer.batch_decode(dev_set['context_vecs'])\n",
    "\n",
    "    split_datasets = pickle.load(open('{}/cui_based_datasets.p'.format(data_name),'rb'))\n",
    "    cui_dev_set = split_datasets['valid']\n",
    "\n",
    "    logits_flat = []\n",
    "    for l in logits:\n",
    "        logits_flat.extend(l)\n",
    "\n",
    "    labels_flat = []\n",
    "    for l in labels:\n",
    "        labels_flat.extend(l)\n",
    "\n",
    "    assert len(cui_dev_set) == len(logits_flat) \n",
    "\n",
    "    cui_dev_set['re_ranked_labels'] = labels_flat\n",
    "    cui_dev_set['re_ranked_logits'] = logits_flat\n",
    "    cui_dev_set['re_ranked_preds'] = np.argmax(np.array(logits_flat),axis=1)\n",
    "    \n",
    "    preds = []\n",
    "\n",
    "    for pred, candidates in tqdm(zip(cui_dev_set['re_ranked_preds'], dev_set['candidate_vecs']),total=len(cui_dev_set)):\n",
    "\n",
    "        pred_str = pubmed_bert_tokenizer.decode(candidates[pred])\n",
    "        pred_str = pred_str.replace('[PAD]','').replace('[CLS]','').replace('[SEP]','').strip()\n",
    "\n",
    "        preds.append(pred_str)\n",
    "    \n",
    "    cui_dev_set['re_ranked_pred_strs'] = preds\n",
    "    \n",
    "    correct = []\n",
    "\n",
    "    for i, row in tqdm(cui_dev_set.iterrows()):\n",
    "        query_aui = row.aui\n",
    "        true_cui = row.true_cui\n",
    "        null_cui = row.null_or_cui\n",
    "\n",
    "        if row['re_ranked_labels'] == row['re_ranked_preds']:\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)\n",
    "\n",
    "    cui_dev_set['re_ranked_correct'] = correct\n",
    "\n",
    "    cui_dev_set = dev_df[['aui']].merge(cui_dev_set,on='aui',how='inner')\n",
    "\n",
    "    overall_recall_at_1 = cui_dev_set.re_ranked_correct.mean()\n",
    "    print('Full R@1: {}'.format(overall_recall_at_1))\n",
    "    null_recall = cui_dev_set[cui_dev_set.null_or_cui].re_ranked_correct.mean()\n",
    "    null_precision = cui_dev_set[cui_dev_set['re_ranked_pred_strs'] == 'null'].re_ranked_correct.mean()\n",
    "    print('NULL Recall: {}'.format(null_recall))\n",
    "    print('NULL Precision: {}'.format(null_precision))\n",
    "    non_null_recall_at_1 = cui_dev_set[cui_dev_set.null_or_cui == False].re_ranked_correct.mean() \n",
    "    print('Non-NULL Recall @1: {}'.format(non_null_recall_at_1))\n",
    "    print('=='*20)\n",
    "    \n",
    "    all_performance_metrics.append((add_rba_info, overall_recall_at_1, null_recall, null_precision, non_null_recall_at_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab260ae8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_performance_metrics = pd.DataFrame(all_performance_metrics)\n",
    "all_performance_metrics['f1'] = 2*all_performance_metrics[2]*all_performance_metrics[3]/(all_performance_metrics[2] + all_performance_metrics[3])\n",
    "all_performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd6f1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dev_df.groupby('sem_group').count().sort_values('aui',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34748101",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rw_uva",
   "language": "python",
   "name": "rw_uva"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
